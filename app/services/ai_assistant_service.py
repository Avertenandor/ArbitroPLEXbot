"""
AI Assistant Service.

Provides integration with Anthropic Claude API for intelligent
assistant functionality with role-based access control.

Refactored: prompts, tools, and executor moved to app/services/ai/ module.
"""

from datetime import UTC, datetime
from typing import Any

from loguru import logger

from app.config.operational_constants import (
    AI_MAX_TOKENS_LONG,
    AI_MAX_TOKENS_MEDIUM,
    AI_MAX_TOKENS_SHORT,
)
from app.config.security import (
    ARYA_COMMAND_GIVERS,
    ARYA_TEACHERS,
    TECH_DEPUTIES,
    can_command_arya,
    can_teach_arya,
    is_super_admin,
)

# Import from new ai module
from app.services.ai import (
    AI_NAME,
    ROLE_DESCRIPTIONS,
    SYSTEM_PROMPT_ADMIN,
    SYSTEM_PROMPT_BASE,
    SYSTEM_PROMPT_SUPER_ADMIN,
    SYSTEM_PROMPT_TECH_DEPUTY,
    SYSTEM_PROMPT_USER,
    ToolExecutor,
    UserRole,
    extract_text_from_response,
    get_all_admin_tools,
    get_api_error_message,
    get_system_prompt,
    get_user_wallet_tools,
    wrap_system_prompt,
)


try:
    import anthropic

    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False
    anthropic = None


class AIAssistantService:
    """
    AI Assistant service using Anthropic Claude API.

    Provides role-based intelligent assistance with different
    access levels for users, admins and super admins.
    """

    def __init__(self, api_key: str | None = None) -> None:
        """
        Initialize AI assistant.

        Args:
            api_key: Anthropic API key
        """
        self.api_key = api_key
        self.client = None
        # Models: Sonnet for complex, Haiku for simple (12x cheaper!)
        self.model_sonnet = "claude-sonnet-4-20250514"  # Complex tasks
        self.model_haiku = "claude-haiku-4-5-20251001"  # Simple tasks (12x cheaper)
        self.model = self.model_sonnet  # Default

        # Cache for system prompts (reusable across sessions)
        self._cached_system_prompts: dict[str, str] = {}

        if api_key and ANTHROPIC_AVAILABLE:
            try:
                self.client = anthropic.Anthropic(api_key=api_key)
                logger.info("AI Assistant initialized with Anthropic API")
            except Exception as e:
                logger.error(f"Failed to initialize Anthropic client: {e}")
                self.client = None
        elif not ANTHROPIC_AVAILABLE:
            logger.warning("Anthropic package not installed")
        else:
            logger.warning("No Anthropic API key provided")

    def _get_system_prompt(self, role: UserRole, username: str | None = None, telegram_id: int | None = None) -> str:
        """Get system prompt based on user role, telegram_id and username."""
        # SECURITY: Check telegram_id FIRST, then username as fallback
        # Tech deputy ID: 1691026253 (@AI_XAN)
        if telegram_id == 1691026253:
            return SYSTEM_PROMPT_TECH_DEPUTY

        # Fallback to username only if telegram_id not provided (backwards compat)
        if telegram_id is None and username and username.replace("@", "") in TECH_DEPUTIES:
            logger.warning(f"TECH_DEPUTY access by username only: {username}. This is deprecated - use telegram_id!")
            return SYSTEM_PROMPT_TECH_DEPUTY

        if role == UserRole.SUPER_ADMIN:
            return SYSTEM_PROMPT_SUPER_ADMIN
        elif role in (UserRole.ADMIN, UserRole.EXTENDED_ADMIN):
            return SYSTEM_PROMPT_ADMIN
        else:
            return SYSTEM_PROMPT_USER

    def _build_context(
        self,
        role: UserRole,
        user_data: dict[str, Any] | None = None,
        platform_stats: dict[str, Any] | None = None,
        monitoring_data: str | None = None,
    ) -> str:
        """Build context message with user/platform data."""
        context_parts = []

        # Role identification (critical for AI to know who it's talking to)
        role_desc = ROLE_DESCRIPTIONS.get(role, "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å")
        context_parts.append(f"[–†–û–õ–¨ –°–û–ë–ï–°–ï–î–ù–ò–ö–ê: {role_desc.upper()}]")
        context_parts.append("")

        if user_data:
            context_parts.append("–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –°–û–ë–ï–°–ï–î–ù–ò–ö–ï:")
            for key, value in user_data.items():
                context_parts.append(f"- {key}: {value}")
            context_parts.append("")

        # Add knowledge base - USE COMPACT VERSION to save tokens!
        # Full KB = ~9000 tokens, Compact KB = ~1500 tokens (saves 83%)
        try:
            from app.services.knowledge_base import get_knowledge_base

            kb = get_knowledge_base()
            # Use compact version instead of full KB
            kb_context = kb.format_compact()
            if kb_context:
                context_parts.append(kb_context)
                context_parts.append("")
        except Exception as e:
            logger.debug(f"Knowledge base not available: {e}")

        # Add real monitoring data for admins (but limit size)
        if monitoring_data and role != UserRole.USER:
            # Truncate monitoring data to save tokens
            if len(monitoring_data) > 2000:
                monitoring_data = monitoring_data[:2000] + "\n... (—Å–æ–∫—Ä–∞—â–µ–Ω–æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏)"
            context_parts.append(monitoring_data)
            context_parts.append("")

        if platform_stats and role != UserRole.USER:
            context_parts.append("–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            for key, value in platform_stats.items():
                context_parts.append(f"- {key}: {value}")

        return "\n".join(context_parts) if context_parts else ""

    def _select_model(self, message: str, role: UserRole) -> str:
        """
        Select optimal model based on message complexity.

        Haiku is 12x cheaper ($0.25/$1.25 vs $3/$15 per 1M tokens).
        Use Haiku for simple queries, Sonnet for complex analysis.

        Args:
            message: User message
            role: User role

        Returns:
            Model name to use
        """
        message_lower = message.lower()

        # Complex keywords requiring Sonnet (analytical, strategic, tools)
        complex_keywords = [
            # Tool usage (always Sonnet for reliability)
            "–ø–æ–∫–∞–∂–∏",
            "–Ω–∞–π–¥–∏",
            "–ø–æ–∏—Å–∫",
            "—Å–æ–∑–¥–∞–π",
            "–∏–∑–º–µ–Ω–∏",
            "—É–¥–∞–ª–∏",
            "–æ—Ç–º–µ–Ω–∏",
            "–Ω–∞—á–∏—Å–ª–∏",
            "–∑–∞–±–ª–æ–∫–∏—Ä—É–π",
            "—Ä–∞–∑–±–ª–æ–∫–∏—Ä—É–π",
            "–æ–¥–æ–±—Ä–∏",
            "–æ—Ç–∫–ª–æ–Ω–∏",
            "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫",
            "–æ—Ç—á—ë—Ç",
            "–∞–Ω–∞–ª–∏—Ç–∏–∫",
            "–∞–Ω–∞–ª–∏–∑",
            # Complex questions
            "–ø–æ—á–µ–º—É",
            "–æ–±—ä—è—Å–Ω–∏ –ø–æ–¥—Ä–æ–±–Ω–æ",
            "–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç",
            "—Å—Ç—Ä–∞—Ç–µ–≥–∏",
            "—Å—Ä–∞–≤–Ω–∏",
            "—Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É",
            "–ø–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã",
            # Financial analysis
            "–¥–µ–ø–æ–∑–∏—Ç",
            "–≤—ã–≤–æ–¥",
            "–±–∞–ª–∞–Ω—Å",
            "roi",
            "–¥–æ—Ö–æ–¥",
            "–ø—Ä–∏–±—ã–ª—å",
            # Admin tools
            "–æ–±—Ä–∞—â–µ–Ω–∏",
            "—Ç–∏–∫–µ—Ç",
            "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª",
            "–∞–¥–º–∏–Ω",
            "–ª–æ–≥–∏",
            # Security
            "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç",
            "–≤–µ—Ä–∏—Ñ–∏–∫",
            "–ø—Ä–æ–≤–µ—Ä—å",
            "–ø–æ–¥–æ–∑—Ä–∏",
        ]

        # Simple keywords - can use Haiku (greetings, navigation, simple FAQ)
        simple_keywords = [
            "–ø—Ä–∏–≤–µ—Ç",
            "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π",
            "–¥–æ–±—Ä—ã–π",
            "–ø–æ–∫–∞",
            "—Å–ø–∞—Å–∏–±–æ",
            "–±–ª–∞–≥–æ–¥–∞—Ä",
            "—á—Ç–æ —Ç–∞–∫–æ–µ",
            "–∫–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è",
            "–≥–¥–µ –Ω–∞–π—Ç–∏",
            "–∫–∞–∫–∞—è –∫–Ω–æ–ø–∫–∞",
            "–ø–æ–º–æ—â—å",
            "help",
            "—Å—Ç–∞—Ä—Ç",
            "start",
            "–º–µ–Ω—é",
            "–¥–∞",
            "–Ω–µ—Ç",
            "–æ–∫",
            "–ø–æ–Ω—è–ª",
            "—è—Å–Ω–æ",
            "—Ö–æ—Ä–æ—à–æ",
        ]

        # Check for complex keywords first
        for keyword in complex_keywords:
            if keyword in message_lower:
                logger.debug(f"Token economy: Using Sonnet (complex keyword: {keyword})")
                return self.model_sonnet

        # If message is short and simple - use Haiku
        if len(message) < 50 and any(kw in message_lower for kw in simple_keywords):
            logger.debug("Token economy: Using Haiku (simple message)")
            return self.model_haiku

        # Admins get Sonnet by default (they usually need tools)
        if role in (UserRole.SUPER_ADMIN, UserRole.ADMIN, UserRole.EXTENDED_ADMIN):
            logger.debug("Token economy: Using Sonnet (admin role)")
            return self.model_sonnet

        # For regular users with medium-length messages - Haiku
        if len(message) < 200 and role == UserRole.USER:
            logger.debug("Token economy: Using Haiku (regular user, short message)")
            return self.model_haiku

        # Default to Sonnet for safety
        logger.debug("Token economy: Using Sonnet (default)")
        return self.model_sonnet

    async def chat(
        self,
        message: str,
        role: UserRole = UserRole.USER,
        user_data: dict[str, Any] | None = None,
        platform_stats: dict[str, Any] | None = None,
        monitoring_data: str | None = None,
        conversation_history: list[dict] | None = None,
    ) -> str:
        """
        Send message to AI and get response.

        Args:
            message: User's message
            role: User's role for access control
            user_data: Optional user context data
            platform_stats: Optional platform statistics (for admins)
            monitoring_data: Real-time monitoring data (formatted text)
            conversation_history: Optional previous messages

        Returns:
            AI response text
        """
        if not self.client:
            return (
                f"ü§ñ –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, {AI_NAME} –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. "
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É."
            )

        try:
            # Extract username and telegram_id from user_data for access checks
            username = None
            telegram_id = None
            if user_data:
                username = user_data.get("username") or user_data.get("–ò–º—è")
                telegram_id = user_data.get("ID") or user_data.get("telegram_id")
                if isinstance(telegram_id, str):
                    try:
                        telegram_id = int(telegram_id)
                    except ValueError:
                        telegram_id = None

            # Build messages
            messages = []

            # Add context as first user message if available
            context = self._build_context(role, user_data, platform_stats, monitoring_data)
            if context:
                messages.append({"role": "user", "content": f"[–ö–û–ù–¢–ï–ö–°–¢ –°–ò–°–¢–ï–ú–´]\n{context}"})
                messages.append({"role": "assistant", "content": f"–ü–æ–Ω—è–ª. –Ø {AI_NAME}, –≥–æ—Ç–æ–≤–∞ –ø–æ–º–æ—á—å!"})

            # Add conversation history
            if conversation_history:
                messages.extend(conversation_history[-10:])  # Last 10 messages

            # Add current message
            messages.append({"role": "user", "content": message})

            # Get system prompt (with telegram_id for secure tech deputy check)
            system_prompt = self._get_system_prompt(role, username, telegram_id)

            # Smart model selection: use Haiku for simple queries (12x cheaper!)
            # Haiku: $0.25/$1.25 per 1M tokens vs Sonnet: $3/$15
            selected_model = self._select_model(message, role)

            # Use prompt caching for system prompt (saves 90% on repeated calls)
            # https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching
            system_with_cache = [{"type": "text", "text": system_prompt, "cache_control": {"type": "ephemeral"}}]

            # Call Claude API with caching
            response = self.client.messages.create(
                model=selected_model,
                max_tokens=AI_MAX_TOKENS_SHORT,
                system=system_with_cache,
                messages=messages,
            )

            # Extract text response (safely check for text attribute)
            if response.content and len(response.content) > 0:
                first_block = response.content[0]
                if hasattr(first_block, "text") and first_block.text:
                    return first_block.text

            return "ü§ñ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."

        except Exception as e:
            logger.error(f"AI chat error: {type(e).__name__}: {e}")
            return get_api_error_message(e)

    async def get_quick_help(self, topic: str, role: UserRole) -> str:
        """
        Get quick help on a specific topic.

        Args:
            topic: Help topic
            role: User role

        Returns:
            Help text
        """
        prompts = {
            "deposit": "–û–±—ä—è—Å–Ω–∏ –∫—Ä–∞—Ç–∫–æ –∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å –¥–µ–ø–æ–∑–∏—Ç –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ",
            "withdrawal": "–û–±—ä—è—Å–Ω–∏ –∫—Ä–∞—Ç–∫–æ –∫–∞–∫ –≤—ã–≤–µ—Å—Ç–∏ —Å—Ä–µ–¥—Å—Ç–≤–∞",
            "referral": "–û–±—ä—è—Å–Ω–∏ –∫—Ä–∞—Ç–∫–æ –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞",
            "bonus": "–û–±—ä—è—Å–Ω–∏ –∫—Ä–∞—Ç–∫–æ –∫–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç –±–æ–Ω—É—Å—ã",
            "plex": "–û–±—ä—è—Å–Ω–∏ –∫—Ä–∞—Ç–∫–æ –∑–∞—á–µ–º –Ω—É–∂–Ω—ã —Ç–æ–∫–µ–Ω—ã PLEX",
            "roi": "–û–±—ä—è—Å–Ω–∏ –∫—Ä–∞—Ç–∫–æ –∫–∞–∫ –Ω–∞—á–∏—Å–ª—è–µ—Ç—Å—è –¥–æ—Ö–æ–¥",
        }

        prompt = prompts.get(topic, f"–î–∞–π –∫—Ä–∞—Ç–∫—É—é —Å–ø—Ä–∞–≤–∫—É –ø–æ —Ç–µ–º–µ: {topic}")
        return await self.chat(prompt, role=role)

    def is_available(self) -> bool:
        """Check if AI service is available."""
        return self.client is not None

    async def extract_knowledge(
        self,
        conversation: list[dict],
        source_user: str,
        source_telegram_id: int | None = None,
    ) -> list[dict] | None:
        """
        Extract knowledge from conversation to add to knowledge base.

        –í–ê–ñ–ù–û: –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ –¥–ª—è –í–°–ï–• –∞–¥–º–∏–Ω–æ–≤,
        –∫–æ—Ç–æ—Ä—ã–µ –æ–±—â–∞—é—Ç—Å—è —Å –ê—Ä—å–µ–π –≤ –∞–¥–º–∏–Ω—Å–∫–æ–º —Ä–µ–∂–∏–º–µ.
        –î–æ—Å—Ç—É–ø –∫ —ç—Ç–æ–º—É —Ä–µ–∂–∏–º—É —É–∂–µ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç—Å—è middleware –∏
        get_admin_or_deny(), –ø–æ—ç—Ç–æ–º—É –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∂—ë—Å—Ç–∫–∏–π
        whitelist (ARYA_TEACHERS) –∑–¥–µ—Å—å –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è.

        Args:
            conversation: List of message dicts with role and content
            source_user: Username of the person in conversation
            source_telegram_id: Telegram ID for authorization check

        Returns:
            List of extracted Q&A pairs or None
        """
        if not self.client:
            return None

        # –†–ê–ù–¨–®–ï: –∑–¥–µ—Å—å –±—ã–ª –∂—ë—Å—Ç–∫–∏–π whitelist —á–µ—Ä–µ–∑ can_teach_arya()
        # –∏ —É—á–∏—Ç—å –ê—Ä—å—é –º–æ–≥–ª–∏ —Ç–æ–ª—å–∫–æ ARYA_TEACHERS.
        # –¢–ï–ü–ï–†–¨: –ª—é–±—ã–µ –∞–¥–º–∏–Ω—ã, –∏–º–µ—é—â–∏–µ –¥–æ—Å—Ç—É–ø –∫ –∞–¥–º–∏–Ω—Å–∫–æ–º—É
        # AI-—Ö–µ–Ω–¥–ª–µ—Ä—É, –º–æ–≥—É—Ç –æ–±—É—á–∞—Ç—å –ê—Ä—å—é. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        # –Ω–∞ –ø—Ä–∞–≤–∞ —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ö–µ–Ω–¥–ª–µ—Ä–æ–≤.

        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–ª—å —É—á–∏—Ç–µ–ª—è –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
            teacher_role = (
                "–ö–û–ú–ê–ù–î–ò–†–û–ú" if source_telegram_id and is_super_admin(source_telegram_id) else "–ê–î–ú–ò–ù–ò–°–¢–†–ê–¢–û–†–û–ú"
            )

            extraction_prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É {teacher_role} ({source_user}) –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã ArbitroPLEX –∏ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º ARIA.

–¢–í–û–Ø –ó–ê–î–ê–ß–ê: –ò–∑–≤–ª–µ—á—å –õ–Æ–ë–´–ï –ü–û–õ–ï–ó–ù–´–ï –ó–ù–ê–ù–ò–Ø, –§–ê–ö–¢–´ –∏ –ò–ù–°–¢–†–£–ö–¶–ò–ò –∏–∑ —Å–ª–æ–≤ –ö–æ–º–∞–Ω–¥–∏—Ä–∞.

–ß–¢–û –ò–ó–í–õ–ï–ö–ê–¢–¨ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç):
1. –§–ê–ö–¢–´ –û –ü–†–û–ï–ö–¢–ê–•: –õ—é–±–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–æ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö, –∫—Ä–æ–ª–∏–∫–∞—Ö, NFT, FreeTube, PLEX –∏ —Ç.–¥.
2. –ë–ò–ó–ù–ï–°-–ú–û–î–ï–õ–ò: –ö–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏, –æ—Ç–∫—É–¥–∞ –¥–æ—Ö–æ–¥, –º–µ—Ö–∞–Ω–∏–∫–∞ –Ω–∞—á–∏—Å–ª–µ–Ω–∏–π.
3. –ò–ù–°–¢–†–£–ö–¶–ò–ò: –ö–∞–∫ –æ–±—â–∞—Ç—å—Å—è, —á—Ç–æ –æ—Ç–≤–µ—á–∞—Ç—å, —Å—Ç–∏–ª—å –ø–æ–≤–µ–¥–µ–Ω–∏—è.
4. –ü–†–ê–í–ò–õ–ê: –ó–∞–ø—Ä–µ—Ç—ã, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏.

–ï–°–õ–ò –ö–û–ú–ê–ù–î–ò–† –†–ê–°–°–ö–ê–ó–´–í–ê–ï–¢ –û –ù–û–í–û–ú –ü–†–û–ï–ö–¢–ï (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ –∫—Ä–æ–ª–∏–∫–æ–≤):
- –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å—ã —Ç–∞–∫, –∫–∞–∫ –∏—Ö –∑–∞–¥–∞–ª –±—ã –∏–Ω–≤–µ—Å—Ç–æ—Ä (–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç? –û—Ç–∫—É–¥–∞ –¥–æ—Ö–æ–¥? –í —á–µ–º —Å—É—Ç—å?).
- –í –æ—Ç–≤–µ—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏ –í–°–ï –∫–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏ (—Ü–∏—Ñ—Ä—ã, –º–µ—Ö–∞–Ω–∏–∫–∞, –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞).

–ù–ï –ò–ó–í–õ–ï–ö–ê–ô:
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã (—Ç–∏–ø–∞ /start)
- –°–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö
- –ü—É—Å—Ç—É—é –±–æ–ª—Ç–æ–≤–Ω—é ("–ø—Ä–∏–≤–µ—Ç", "–∫–∞–∫ –¥–µ–ª–∞")

–í–ê–ñ–ù–û:
- –ï—Å–ª–∏ –ö–æ–º–∞–Ω–¥–∏—Ä –¥–µ–ª–∏—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π - —ç—Ç–æ –ó–ù–ê–ù–ò–ï! –°–æ—Ö—Ä–∞–Ω—è–π –µ–≥–æ!
- –û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏, –Ω–æ –±–µ–∑ –≤–æ–¥—ã.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–¢–û–õ–¨–ö–û JSON –º–∞—Å—Å–∏–≤):
[
  {
                "question": "–í–æ–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä: –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –º–æ–¥–µ–ª—å –∫—Ä–æ–ª–∏–∫–æ–≤?)",
    "answer": "–û—Ç–≤–µ—Ç (—Å—É—Ç—å –º–µ—Ö–∞–Ω–∏–∫–∏, —Ñ–∞–∫—Ç—ã)",
    "category": "–≠–∫–æ—Å–∏—Å—Ç–µ–º–∞ / NFT / –ü—Ä–∞–≤–∏–ª–∞ / –∏ —Ç.–¥."
  }
]

–í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–π –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –∫–∞–∫–∞—è-—Ç–æ –ø–æ–ª–µ–∑–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è!
–ï—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ –ø–æ–ª–µ–∑–Ω–æ–≥–æ –Ω–µ—Ç, –æ—Ç–≤–µ—Ç—å: []
"""

            messages = [
                {"role": "user", "content": extraction_prompt},
                {"role": "assistant", "content": "–ü–æ–Ω—è–ª, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∏–∞–ª–æ–≥..."},
                {
                    "role": "user",
                    "content": "–î–∏–∞–ª–æ–≥:\n" + "\n".join(f"{m['role']}: {m['content']}" for m in conversation[-20:]),
                },
            ]

            # Use prompt caching for system prompt (saves 90% on repeated calls)
            system_prompt = (
                "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –º–∞—Å—Å–∏–≤–æ–º. –û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ö–†–ê–¢–ö–ò–ú–ò."
            )
            system_with_cache = [{"type": "text", "text": system_prompt, "cache_control": {"type": "ephemeral"}}]

            response = self.client.messages.create(
                model=self.model_haiku,  # Use Haiku for extraction (12x cheaper)
                max_tokens=AI_MAX_TOKENS_LONG,
                system=system_with_cache,
                messages=messages,
            )

            if response.content and len(response.content) > 0:
                import json
                import re

                first_block = response.content[0]
                if not hasattr(first_block, "text") or not first_block.text:
                    return None
                text = first_block.text.strip()

                # Try to extract JSON array from response
                # Sometimes Claude adds extra text before/after JSON
                json_match = re.search(r"\[[\s\S]*?\]", text)  # Non-greedy to capture only first JSON array
                if json_match:
                    json_text = json_match.group(0)
                    try:
                        return json.loads(json_text)
                    except json.JSONDecodeError as je:
                        logger.warning(f"JSON parse error in extracted text: {je}")

                # Fallback: try direct parse if starts with [
                if text.startswith("["):
                    try:
                        return json.loads(text)
                    except json.JSONDecodeError:
                        pass

                logger.debug(f"Could not extract JSON from: {text[:200]}")

        except Exception as e:
            logger.error(f"Knowledge extraction error: {e}")

        return None

    async def save_learned_knowledge(
        self,
        qa_pairs: list[dict],
        source_user: str,
    ) -> int:
        """
        Save extracted knowledge to knowledge base.

        Args:
            qa_pairs: List of Q&A dictionaries with question, answer, category
            source_user: Username of the source

        Returns:
            Number of successfully saved entries
        """
        # Validate input
        if not qa_pairs:
            logger.debug("save_learned_knowledge: empty qa_pairs, nothing to save")
            return 0

        if not isinstance(qa_pairs, list):
            logger.warning(f"save_learned_knowledge: qa_pairs is not a list: {type(qa_pairs)}")
            return 0

        try:
            from app.services.knowledge_base import get_knowledge_base

            kb = get_knowledge_base()
            saved = 0

            for qa in qa_pairs:
                # Validate each entry
                if not isinstance(qa, dict):
                    logger.warning(f"save_learned_knowledge: skipping non-dict entry: {type(qa)}")
                    continue

                question = qa.get("question", "").strip() if qa.get("question") else ""
                answer = qa.get("answer", "").strip() if qa.get("answer") else ""

                if not question or not answer:
                    logger.debug(f"save_learned_knowledge: skipping empty Q&A: q={bool(question)}, a={bool(answer)}")
                    continue

                # Limit entry size to prevent bloat
                if len(question) > 500:
                    question = question[:500] + "..."
                if len(answer) > 2000:
                    answer = answer[:2000] + "..."

                try:
                    kb.add_learned_entry(
                        question=question,
                        answer=answer,
                        category=qa.get("category", "–ò–∑ –¥–∏–∞–ª–æ–≥–æ–≤"),
                        source_user=source_user,
                        needs_verification=True,
                    )
                    saved += 1
                except Exception as entry_error:
                    logger.error(f"save_learned_knowledge: failed to save entry: {entry_error}")
                    continue

            logger.info(f"save_learned_knowledge: saved {saved}/{len(qa_pairs)} entries from {source_user}")
            return saved

        except ImportError as e:
            logger.error(f"save_learned_knowledge: knowledge_base import failed: {e}")
            return 0
        except Exception as e:
            logger.error(f"save_learned_knowledge: unexpected error: {e}")
            return 0

    # ========== USER CHAT WITH WALLET TOOLS ==========

    async def chat_user_with_wallet(
        self,
        message: str,
        user_telegram_id: int,
        user_data: dict[str, Any] | None = None,
        conversation_history: list[dict] | None = None,
        session: Any = None,
    ) -> str:
        """
        Chat for regular users with wallet balance tools.

        Allows ARIA to check user's wallet and recommend PLEX purchases.

        Args:
            message: User's message
            user_telegram_id: User's Telegram ID
            user_data: Optional user context
            conversation_history: Previous messages
            session: Database session

        Returns:
            AI response text
        """
        if not self.client:
            return f"ü§ñ –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, {AI_NAME} –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."

        try:
            tools = get_user_wallet_tools()

            messages = []

            # Add context
            context = self._build_context(UserRole.USER, user_data, None, None)
            if context:
                messages.append({"role": "user", "content": f"[–ö–û–ù–¢–ï–ö–°–¢]\n{context}"})
                messages.append({"role": "assistant", "content": f"–ü–æ–Ω—è–ª. –Ø {AI_NAME}!"})

            if conversation_history:
                messages.extend(conversation_history[-10:])

            messages.append({"role": "user", "content": message})

            system_prompt = self._get_system_prompt(UserRole.USER, None, user_telegram_id)

            # Use prompt caching for system prompt
            system_with_cache = [{"type": "text", "text": system_prompt, "cache_control": {"type": "ephemeral"}}]

            # First call - use Haiku for users (cheaper)
            response = self.client.messages.create(
                model=self.model_haiku,  # Users get Haiku (12x cheaper)
                max_tokens=AI_MAX_TOKENS_SHORT,
                system=system_with_cache,
                messages=messages,
                tools=tools,
            )

            # Handle tool use
            if response.stop_reason == "tool_use":
                if not session:
                    logger.error(f"Tool use requested but session is None for user {user_telegram_id}")
                    return "ü§ñ –û—à–∏–±–∫–∞: —Å–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

                tool_results = await self._execute_user_wallet_tools(response.content, user_telegram_id, session)

                # Serialize response.content to JSON-compatible format
                assistant_content = []
                for block in response.content:
                    if hasattr(block, "type"):
                        if block.type == "text":
                            assistant_content.append({"type": "text", "text": block.text})
                        elif block.type == "tool_use":
                            assistant_content.append(
                                {
                                    "type": "tool_use",
                                    "id": block.id,
                                    "name": block.name,
                                    "input": block.input,
                                }
                            )
                messages.append({"role": "assistant", "content": assistant_content})
                messages.append({"role": "user", "content": tool_results})

                # Get final response (no tools - final answer should be text only)
                response = self.client.messages.create(
                    model=self.model_haiku,  # Keep Haiku for users
                    max_tokens=AI_MAX_TOKENS_SHORT,
                    system=system_with_cache,
                    messages=messages,
                )

            # Extract text
            for block in response.content:
                if hasattr(block, "text"):
                    return block.text

            return "ü§ñ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."

        except Exception as e:
            logger.error(f"User wallet chat error: {e}")
            return "ü§ñ –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

    async def _execute_user_wallet_tools(
        self,
        content: list,
        user_telegram_id: int,
        session: Any,
    ) -> list[dict]:
        """Execute wallet tools for user."""
        from app.services.ai_wallet_service import AIWalletService

        tool_results = []

        for block in content:
            if block.type == "tool_use":
                tool_name = block.name
                result = {"error": "Unknown tool"}

                try:
                    wallet_service = AIWalletService(session)

                    if tool_name == "check_my_wallet":
                        result = await wallet_service.check_user_wallet(user_identifier=str(user_telegram_id))
                    elif tool_name == "get_current_plex_rate":
                        result = await wallet_service.get_plex_rate()

                except Exception as e:
                    logger.error(f"User wallet tool error: {e}")
                    result = {"error": str(e)}

                tool_results.append(
                    {
                        "type": "tool_result",
                        "tool_use_id": block.id,
                        "content": str(result),
                    }
                )

        return tool_results

    # ========== BROADCAST FUNCTIONS FOR –ö–û–ú–ê–ù–î–ò–† ==========

    async def chat_with_tools(
        self,
        message: str,
        role: UserRole,
        user_data: dict[str, Any] | None = None,
        platform_stats: dict[str, Any] | None = None,
        monitoring_data: str | None = None,
        conversation_history: list[dict] | None = None,
        session: Any = None,
        bot: Any = None,
    ) -> str:
        """
        Chat with tool/function calling support.

        –í–ê–ñ–ù–û: –ê—Ä—å—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–∞–Ω–¥—ã –æ—Ç –ê–í–¢–û–†–ò–ó–û–í–ê–ù–ù–´–• –ê–î–ú–ò–ù–û–í!
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ can_command_arya() - —Å–ø–∏—Å–æ–∫ –≤ security.py.

        –ê—Ä—å—è —Å–∞–º–∞ —è–≤–ª—è–µ—Ç—Å—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º (extended_admin) –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç
        –∫–æ–º–∞–Ω–¥—ã –æ—Ç –∏–º–µ–Ω–∏ —Å–∏—Å—Ç–µ–º—ã, –ù–ï –æ—Ç –∏–º–µ–Ω–∏ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞.

        Args:
            message: User message
            role: User role
            user_data: User context
            platform_stats: Platform stats
            monitoring_data: Monitoring data
            conversation_history: Previous messages
            session: Database session for broadcast
            bot: Bot instance for sending messages

        Returns:
            AI response
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º telegram_id —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–∞–≤
        caller_telegram_id: int | None = None
        if user_data:
            caller_telegram_id = user_data.get("ID") or user_data.get("telegram_id")
            if isinstance(caller_telegram_id, str):
                try:
                    caller_telegram_id = int(caller_telegram_id)
                except ValueError:
                    caller_telegram_id = None

        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–∂–µ—Ç –ª–∏ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫ –∫–æ–º–∞–Ω–¥–æ–≤–∞—Ç—å –ê—Ä—å–µ–π.
        # –†–∞–Ω—å—à–µ —Ç—É—Ç –±—ã–ª –∂—ë—Å—Ç–∫–∏–π whitelist (ARYA_COMMAND_GIVERS).
        # –¢–µ–ø–µ—Ä—å –ª—é–±–æ–º—É –¥–µ–π—Å—Ç–≤—É—é—â–µ–º—É –∞–¥–º–∏–Ω—É (–µ—Å—Ç—å –∑–∞–ø–∏—Å—å –≤ –ë–î –∏ –æ–Ω –Ω–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω)
        # —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –æ—Ç–¥–∞–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã, –∞ —É–∂–µ –≤–Ω—É—Ç—Ä–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        # –Ω–∞–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –ø–æ –µ–≥–æ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–æ–ª–∏ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º –≤–Ω—É—Ç—Ä–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
        caller_can_command = False

        if session and caller_telegram_id:
            # 1) –°–Ω–∞—á–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π whitelist –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            if can_command_arya(caller_telegram_id):
                caller_can_command = True
            else:
                # 2) –ï—Å–ª–∏ –Ω–µ –≤ ARYA_COMMAND_GIVERS, –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–π –∞–¥–º–∏–Ω –≤ –ë–î
                try:
                    from app.repositories.admin_repository import AdminRepository

                    admin_repo = AdminRepository(session)
                    admin_obj = await admin_repo.get_by_telegram_id(caller_telegram_id)

                    if admin_obj and not admin_obj.is_blocked:
                        caller_can_command = True
                    else:
                        logger.warning(
                            "ARYA: caller is not allowed to command (not admin or blocked)",
                            extra={"caller_telegram_id": caller_telegram_id},
                        )
                except Exception as e:
                    logger.error(f"ARYA: failed to verify admin rights for caller {caller_telegram_id}: {e}")

        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–µ—Å—Å–∏–∏/–±–æ—Ç–∞ –∏–ª–∏ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫ –Ω–µ –º–æ–∂–µ—Ç –∫–æ–º–∞–Ω–¥–æ–≤–∞—Ç—å - –æ–±—ã—á–Ω—ã–π —á–∞—Ç
        if not session or not bot or not caller_can_command:
            # –î–ª—è –æ–±—ã—á–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –Ω–µ–∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö - —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            return await self.chat(message, role, user_data, platform_stats, monitoring_data, conversation_history)

        # –ê—Ä—å—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–∞–Ω–¥—ã –∫–∞–∫ SUPER_ADMIN –¥–ª—è –ª—é–±–æ–≥–æ –¥–µ–π—Å—Ç–≤—É—é—â–µ–≥–æ –∞–¥–º–∏–Ω–∞.
        # (–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ: –≤—Å–µ –∞–¥–º–∏–Ω—ã –º–æ–≥—É—Ç –∫–æ–º–∞–Ω–¥–æ–≤–∞—Ç—å –ê—Ä—å–µ–π ¬´–∫–∞–∫ —Å—É–ø–µ—Ä –∞–¥–º–∏–Ω¬ª.)
        arya_role = UserRole.SUPER_ADMIN

        if not self.client:
            return f"ü§ñ –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, {AI_NAME} –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

        try:
            # –í–ê–ñ–ù–û: –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –ø–æ —Ä–æ–ª–∏ –ê–†–¨–ò, –Ω–µ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞!
            # –ê—Ä—å—è - extended_admin (–∏–ª–∏ super_admin –¥–ª—è –ö–æ–º–∞–Ω–¥–∏—Ä–∞)
            tools = get_all_admin_tools(arya_role)
            logger.info(f"ARYA: executing commands from telegram_id={caller_telegram_id}, arya_role={arya_role.value}")

            # Extract username and telegram_id
            username = None
            telegram_id = None
            if user_data:
                username = user_data.get("username") or user_data.get("–ò–º—è")
                telegram_id = user_data.get("ID") or user_data.get("telegram_id")
                if isinstance(telegram_id, str):
                    try:
                        telegram_id = int(telegram_id)
                    except ValueError:
                        telegram_id = None

            # Build messages
            messages = []

            context = self._build_context(role, user_data, platform_stats, monitoring_data)
            if context:
                messages.append({"role": "user", "content": f"[–ö–û–ù–¢–ï–ö–°–¢ –°–ò–°–¢–ï–ú–´]\n{context}"})
                messages.append(
                    {
                        "role": "assistant",
                        "content": f"–ü–æ–Ω—è–ª. –Ø {AI_NAME}, –≥–æ—Ç–æ–≤–∞ –ø–æ–º–æ—á—å! –£ –º–µ–Ω—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º —Ä–∞—Å—Å—ã–ª–∫–∏.",
                    }
                )

            if conversation_history:
                messages.extend(conversation_history[-10:])

            messages.append({"role": "user", "content": message})

            system_prompt = self._get_system_prompt(role, username, telegram_id)

            # First call - may request tool use
            # Use prompt caching (saves 90% on repeated calls)
            system_with_cache = wrap_system_prompt(system_prompt)

            response = self.client.messages.create(
                model=self.model,
                max_tokens=AI_MAX_TOKENS_MEDIUM,
                system=system_with_cache,
                messages=messages,
                tools=tools,
            )

            # Check if tool use requested
            if response.stop_reason == "tool_use":
                # Execute tools using ToolExecutor
                # –í–ê–ñ–ù–û: –ø–µ—Ä–µ–¥–∞—ë–º caller_telegram_id –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ rate limiting
                executor = ToolExecutor(
                    session,
                    bot,
                    user_data,
                    caller_telegram_id=caller_telegram_id,
                )
                tool_results = await executor.execute(
                    response.content,
                    resolve_admin_id_func=self._resolve_admin_id,
                )

                # Convert response.content to serializable format for messages
                # Anthropic SDK returns ContentBlock objects, need to convert to dicts
                assistant_content = []
                for block in response.content:
                    if hasattr(block, "type"):
                        if block.type == "text":
                            assistant_content.append({"type": "text", "text": block.text})
                        elif block.type == "tool_use":
                            assistant_content.append(
                                {
                                    "type": "tool_use",
                                    "id": block.id,
                                    "name": block.name,
                                    "input": block.input,
                                }
                            )

                # Add assistant response and tool results
                messages.append(
                    {
                        "role": "assistant",
                        "content": assistant_content,
                    }
                )
                messages.append(
                    {
                        "role": "user",
                        "content": tool_results,
                    }
                )

                # Get final response (no tools - final answer should be text only)
                final_response = self.client.messages.create(
                    model=self.model,
                    max_tokens=AI_MAX_TOKENS_MEDIUM,
                    system=system_with_cache,
                    messages=messages,
                )

                if final_response.content:
                    return self._extract_text_from_response(final_response.content)

            # No tool use, return text directly
            if response.content:
                return self._extract_text_from_response(response.content)

            return "ü§ñ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç."

        except Exception as e:
            logger.error(f"Chat with tools error: {e}")
            # Check if it's an API error
            error_str = str(e).lower()
            if "500" in error_str or "internal server error" in error_str:
                return (
                    "ü§ñ –ò–∑–≤–∏–Ω–∏, —Å–µ–π—á–∞—Å API –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ Anthropic). "
                    "–ü–æ–ø—Ä–æ–±—É–π –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É."
                )
            # Fallback to regular chat for other errors
            try:
                return await self.chat(message, role, user_data, platform_stats, monitoring_data, conversation_history)
            except Exception as fallback_error:
                logger.error(f"Fallback chat also failed: {fallback_error}")
                return "ü§ñ –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Å—å –Ω–∞–ø—Ä—è–º—É—é –∫ –∫–æ–º–∞–Ω–¥–µ."

    async def _resolve_admin_id(
        self,
        identifier: str | int,
        session: Any,
    ) -> dict[str, Any] | None:
        """Resolve admin identifier to telegram_id and username."""
        from app.repositories.admin_repository import AdminRepository

        admin_repo = AdminRepository(session)

        if isinstance(identifier, int):
            admin = await admin_repo.get_by(telegram_id=identifier)
        else:
            identifier = str(identifier).strip()

            # @username
            if identifier.startswith("@"):
                username = identifier[1:]
                admin = await admin_repo.get_by(username=username)
            # Telegram ID as string
            elif identifier.isdigit():
                admin = await admin_repo.get_by(telegram_id=int(identifier))
            else:
                # Try username without @
                admin = await admin_repo.get_by(username=identifier)

        if admin:
            return {
                "telegram_id": admin.telegram_id,
                "username": admin.username,
                "display_name": admin.display_name,
            }
        return None

    def _extract_text_from_response(self, content: list) -> str:
        """Extract text from response content blocks."""
        return extract_text_from_response(content)


# Singleton instance
_ai_service: AIAssistantService | None = None


def get_ai_service() -> AIAssistantService:
    """Get or create AI service singleton."""
    global _ai_service

    if _ai_service is None:
        from app.config.settings import settings

        _ai_service = AIAssistantService(api_key=settings.anthropic_api_key)

    return _ai_service
